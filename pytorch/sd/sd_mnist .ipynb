{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\uttam\\anaconda3\\envs\\envpytorch\\lib\\site-packages (0.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\uttam\\anaconda3\\envs\\envpytorch\\lib\\site-packages (from torchvision) (1.16.2)\n",
      "Requirement already satisfied: six in c:\\users\\uttam\\anaconda3\\envs\\envpytorch\\lib\\site-packages (from torchvision) (1.15.0)\n",
      "Requirement already satisfied: torch in c:\\users\\uttam\\anaconda3\\envs\\envpytorch\\lib\\site-packages (from torchvision) (1.5.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\uttam\\anaconda3\\envs\\envpytorch\\lib\\site-packages (from torchvision) (5.4.1)\n",
      "Requirement already satisfied: future in c:\\users\\uttam\\anaconda3\\envs\\envpytorch\\lib\\site-packages (from torch->torchvision) (0.18.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST('', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = datasets.MNIST('', train=False, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Split: train\n",
       "    Root Location: \n",
       "    Transforms (if any): Compose(\n",
       "                             ToTensor()\n",
       "                         )\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterating over the dataset \n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([3, 7, 0, 7, 4, 1, 3, 8, 7, 0])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = data[0][0],data[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x27e33484d30>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(data[0][0].view(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking label for output , output is balanced or not \n",
    "total = 0\n",
    "counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in trainset:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)] += 1\n",
    "        total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
     ]
    }
   ],
   "source": [
    "print(counter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 9.871666666666666%\n",
      "1: 11.236666666666666%\n",
      "2: 9.93%\n",
      "3: 10.218333333333334%\n",
      "4: 9.736666666666666%\n",
      "5: 9.035%\n",
      "6: 9.863333333333333%\n",
      "7: 10.441666666666666%\n",
      "8: 9.751666666666667%\n",
      "9: 9.915000000000001%\n"
     ]
    }
   ],
   "source": [
    "for i in counter_dict:\n",
    "    print(f\"{i}: {counter_dict[i]/total*100.0}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn #torch.nn gives access to neural network things like  layers\n",
    "import torch.nn.functional as F # give access to function like relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1) # finally layer we will use softmax \n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3806, -2.3096, -2.3491, -2.2344, -2.2219, -2.3972, -2.2282, -2.4475,\n",
       "         -2.2750, -2.2136]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#activation functions are keeping our data scaled between 0 and 1.\n",
    "# just an example.\n",
    "t1= torch.rand((28,28))\n",
    "t1= t1.view(-1,28*28)\n",
    "output = net(t1)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "# loss function and optimiser\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1650'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)# setting gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4982, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0835, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3): # 3 full passes over the data\n",
    "    for data in trainset:  # `data` is a batch of data\n",
    "        X, y = data  # X is the batch of features, y is the batch of targets.\n",
    "        net.zero_grad()  # sets gradients to 0 before loss calc. You will do this likely every step.\n",
    "        output = net(X.view(-1,784))  # pass in the reshaped batch (recall they are 28x28 atm)\n",
    "        loss = F.nll_loss(output, y)  # calc and grab the loss value\n",
    "        loss.backward()  # apply this loss backwards thru the network's parameters\n",
    "        optimizer.step()  # attempt to optimize weights to account for loss/gradients\n",
    "    print(loss)  # print loss. We hope loss (a measure of wrong-ness) declines! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1,784))\n",
    "        #print(output)\n",
    "        for idx, i in enumerate(output):\n",
    "            #print(torch.argmax(i), y[idx])\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.966\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X[0].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(net(X[0].view(-1,784))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.5095e+01, -1.4591e+01, -1.0838e+01, -1.2691e+01, -2.2292e+01,\n",
      "        -2.2176e+01, -4.7869e+01, -2.3246e-05, -2.1595e+01, -1.9245e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "a_featureset = X[0]\n",
    "reshaped_for_network = a_featureset.view(-1,784) # 784 b/c 28*28 image resolution.\n",
    "output = net(reshaped_for_network) #output will be a list of network predictions.\n",
    "first_pred = output[0]\n",
    "print(first_pred)\n",
    "biggest_index = torch.argmax(first_pred)\n",
    "print(biggest_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
