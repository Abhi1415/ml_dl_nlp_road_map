{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Light_gbm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J61GHkbVYIR",
        "colab_type": "text"
      },
      "source": [
        "Light GBM beats all the other algorithms when the dataset is extremely large. Compared to the other algorithms, Light GBM takes lesser time to run on a huge dataset.\n",
        "\n",
        "\n",
        "it is based on decision tree algorithms, it splits the tree leaf wise with the best fit whereas other boosting algorithms split the tree depth wise or level wise rather than leaf-wise. So when growing on the same leaf in Light GBM, the leaf-wise algorithm can reduce more loss than the level-wise algorithm and hence results in much better accuracy which can rarely be achieved by any of the existing boosting algorithms. Also, it is surprisingly very fast, hence the word ‘Light’."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PR-gR3oEXwwe",
        "colab_type": "text"
      },
      "source": [
        "**Level-wise tree growth in XGBOOST**\n",
        "\n",
        "![alt text](https://cdn.analyticsvidhya.com/wp-content/uploads/2017/06/11194110/leaf.png)\n",
        "\n",
        "**Leaf wise tree growth in Light GBM**\n",
        "\n",
        "\n",
        "![alt text](https://cdn.analyticsvidhya.com/wp-content/uploads/2017/06/11194227/depth.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x747LOqjYfJk",
        "colab_type": "text"
      },
      "source": [
        "Leaf wise splits lead to increase in complexity and may lead to overfitting and it can be overcome by specifying another parameter max-depth which specifies the depth to which splitting will occur.\n",
        "\n",
        "**Parameter:** \n",
        "task : default value = train ; options = train , prediction ; Specifies the task we wish to perform which is either train or prediction.\n",
        "\n",
        "application: default=regression, type=enum, options= options :\n",
        "regression : perform regression task\n",
        "binary : Binary classification\n",
        "multiclass: Multiclass Classification\n",
        "lambdarank : lambdarank application\n",
        "\n",
        "data: type=string; training data , LightGBM will train from this data\n",
        "\n",
        "num_iterations: number of boosting iterations to be performed ; default=100; type=int\n",
        "\n",
        "num_leaves : number of leaves in one tree ; default = 31 ; type =int\n",
        "\n",
        "device : default= cpu ; options = gpu,cpu. Device on which we want to train our model. Choose GPU for faster training.\n",
        "\n",
        "max_depth: Specify the max depth to which tree will grow. This parameter is used to deal with overfitting.\n",
        "\n",
        "min_data_in_leaf: Min number of data in one leaf.\n",
        "\n",
        "feature_fraction: default=1 ; specifies the fraction of features to be taken for each iteration.\n",
        "\n",
        "bagging_fraction: default=1 ; specifies the fraction of data to be used for each iteration and is generally used to speed up the training and avoid overfitting.\n",
        "\n",
        "min_gain_to_split: default=.1 ; min gain to perform splitting\n",
        "\n",
        "max_bin : max number of bins to bucket the feature values.\n",
        "\n",
        "min_data_in_bin : min number of data in one bin.\n",
        "\n",
        "num_threads: default=OpenMP_default, type=int ;Number of threads for Light GBM.\n",
        "\n",
        "label : type=string ; specify the label column\n",
        "\n",
        "categorical_feature : type=string ; specify the categorical features we want to use for training our model\n",
        "\n",
        "num_class: default=1 ; type=int ; used only for multi-class classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI84gvHBM4b6",
        "colab_type": "text"
      },
      "source": [
        "**Example:**\n",
        "\n",
        "**LGB on classification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak8nfIXmwqNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkz0e8qqS540",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing libraries\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "from sklearn.datasets import load_breast_cancer,load_boston,load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import mean_squared_error,roc_auc_score,precision_score\n",
        "pd.options.display.max_columns = 999"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjX15zcqS56J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loading the breast cancer dataset\n",
        "X=load_breast_cancer()\n",
        "df=pd.DataFrame(X.data,columns=X.feature_names)\n",
        "Y=X.target "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdqgBUia1XR5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "581909aa-5b99-47a6-9ab0-cba0a17e578a"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0        17.99         10.38          122.80     1001.0          0.11840   \n",
              "1        20.57         17.77          132.90     1326.0          0.08474   \n",
              "2        19.69         21.25          130.00     1203.0          0.10960   \n",
              "3        11.42         20.38           77.58      386.1          0.14250   \n",
              "4        20.29         14.34          135.10     1297.0          0.10030   \n",
              "\n",
              "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0           0.27760          0.3001              0.14710         0.2419   \n",
              "1           0.07864          0.0869              0.07017         0.1812   \n",
              "2           0.15990          0.1974              0.12790         0.2069   \n",
              "3           0.28390          0.2414              0.10520         0.2597   \n",
              "4           0.13280          0.1980              0.10430         0.1809   \n",
              "\n",
              "   mean fractal dimension  radius error  texture error  perimeter error  \\\n",
              "0                 0.07871        1.0950         0.9053            8.589   \n",
              "1                 0.05667        0.5435         0.7339            3.398   \n",
              "2                 0.05999        0.7456         0.7869            4.585   \n",
              "3                 0.09744        0.4956         1.1560            3.445   \n",
              "4                 0.05883        0.7572         0.7813            5.438   \n",
              "\n",
              "   area error  smoothness error  compactness error  concavity error  \\\n",
              "0      153.40          0.006399            0.04904          0.05373   \n",
              "1       74.08          0.005225            0.01308          0.01860   \n",
              "2       94.03          0.006150            0.04006          0.03832   \n",
              "3       27.23          0.009110            0.07458          0.05661   \n",
              "4       94.44          0.011490            0.02461          0.05688   \n",
              "\n",
              "   concave points error  symmetry error  fractal dimension error  \\\n",
              "0               0.01587         0.03003                 0.006193   \n",
              "1               0.01340         0.01389                 0.003532   \n",
              "2               0.02058         0.02250                 0.004571   \n",
              "3               0.01867         0.05963                 0.009208   \n",
              "4               0.01885         0.01756                 0.005115   \n",
              "\n",
              "   worst radius  worst texture  worst perimeter  worst area  worst smoothness  \\\n",
              "0         25.38          17.33           184.60      2019.0            0.1622   \n",
              "1         24.99          23.41           158.80      1956.0            0.1238   \n",
              "2         23.57          25.53           152.50      1709.0            0.1444   \n",
              "3         14.91          26.50            98.87       567.7            0.2098   \n",
              "4         22.54          16.67           152.20      1575.0            0.1374   \n",
              "\n",
              "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
              "0             0.6656           0.7119                0.2654          0.4601   \n",
              "1             0.1866           0.2416                0.1860          0.2750   \n",
              "2             0.4245           0.4504                0.2430          0.3613   \n",
              "3             0.8663           0.6869                0.2575          0.6638   \n",
              "4             0.2050           0.4000                0.1625          0.2364   \n",
              "\n",
              "   worst fractal dimension  \n",
              "0                  0.11890  \n",
              "1                  0.08902  \n",
              "2                  0.08758  \n",
              "3                  0.17300  \n",
              "4                  0.07678  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hygmt2eMS59k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba05671e-b0dd-40d8-c8a7-6567aa466d62"
      },
      "source": [
        "Y[:10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdVXN1tENTjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#scaling the features using Standard Scaler\n",
        "sc=StandardScaler()\n",
        "sc.fit(df)\n",
        "X=pd.DataFrame(sc.fit_transform(df))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFwbHmW2NV3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_test_split \n",
        "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.3,random_state=0)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jf54q5Y4NeSp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "75a4f29b-5a57-46e6-e31a-77a29e0b8d11"
      },
      "source": [
        "#converting the dataset into proper LGB format \n",
        "d_train=lgb.Dataset(X_train, label=y_train)\n",
        "d_train"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightgbm.basic.Dataset at 0x7f8acbe8beb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDeQ6PmwNeUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Specifying the parameter\n",
        "params={}\n",
        "params['learning_rate']=0.03\n",
        "params['boosting_type']='gbdt' #GradientBoostingDecisionTree\n",
        "params['objective']='binary' #Binary target feature\n",
        "params['metric']='binary_logloss' #metric for binary classification\n",
        "params['max_depth']=10"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM3UhdwENeX0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "765919bc-03dc-4b40-95f0-33773e9fa385"
      },
      "source": [
        "#train the model \n",
        "clf=lgb.train(params,d_train,100) #train the model on 100 epocs\n",
        "clf"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightgbm.basic.Booster at 0x7f8acbe9c128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ole_iIcNeeb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prediction on the test set\n",
        "y_pred=clf.predict(X_test)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izVb5IalmmIy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "42d638be-fa10-48ff-d466-67052e5239ba"
      },
      "source": [
        "y_pred[:10]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.04558262, 0.89328757, 0.97349586, 0.97226278, 0.950874  ,\n",
              "       0.97876953, 0.95831269, 0.97355183, 0.96665825, 0.98027443])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQm6dUbSnp9M",
        "colab_type": "text"
      },
      "source": [
        "if>=0.5 ---> 1\n",
        "else ---->0\n",
        "\n",
        "used in build round method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efVIn-Ksm-_h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "af25b23e-068a-4e22-dd0c-6fc8805e4640"
      },
      "source": [
        "#rounding the values\n",
        "y_pred=y_pred.round(0)\n",
        "#converting from float to integer\n",
        "y_pred=y_pred.astype(int)\n",
        "#roc_auc_score metric\n",
        "roc_auc_score(y_pred,y_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.965424739195231"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkrYYQtXnfUh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f2026fa-48d5-4641-f812-b4d4d45be6d7"
      },
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1sJEMmBoRHi",
        "colab_type": "text"
      },
      "source": [
        "**Regression using the Boston dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHNWCiiJoGwA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "4669af5c-2ede-471a-8a7e-76fca3b3c1e1"
      },
      "source": [
        "#loading the Boston Dataset\n",
        "X=load_boston()\n",
        "df=pd.DataFrame(X.data,columns=X.feature_names)\n",
        "Y=X.target\n",
        "#Scaling using the Standard Scaler\n",
        "sc=StandardScaler()\n",
        "sc.fit(df)\n",
        "X=pd.DataFrame(sc.fit_transform(df))\n",
        "#train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.3,random_state=0)\n",
        "#Converting the data into proper LGB Dataset Format\n",
        "d_train=lgb.Dataset(X_train, label=y_train)\n",
        "#Declaring the parameters\n",
        "params={}\n",
        "params['learning_rate']=0.03\n",
        "params['boosting_type']='gbdt' #GradientBoostingDecisionTree\n",
        "params['objective']='regression'#regression task\n",
        "params['n_estimators']=100\n",
        "params['max_depth']=10\n",
        "#model creation and training\n",
        "clf=lgb.train(params,d_train,100)\n",
        "#model prediction on X_test\n",
        "y_pred=clf.predict(X_test)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.1990255464617"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kr39HTiIoG0s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "800b5e81-13d5-4f30-f744-c616bc12cd06"
      },
      "source": [
        "#using RMSE error metric\n",
        "mean_squared_error(y_pred,y_test)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.1990255464617"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9ZFGYhopJJI",
        "colab_type": "text"
      },
      "source": [
        "**Multi-Class Classification using the Wine dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZMlxF16oUNW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loading the dataset\n",
        "X1=load_wine()\n",
        "df_1=pd.DataFrame(X1.data,columns=X1.feature_names)\n",
        "Y_1=X1.target"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jTyJQ0hoc5R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "256a84ee-c2fd-4bbc-fabb-bc085bbccbb9"
      },
      "source": [
        "df_1.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
              "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
              "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
              "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
              "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
              "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
              "\n",
              "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
              "0        3.06                  0.28             2.29             5.64  1.04   \n",
              "1        2.76                  0.26             1.28             4.38  1.05   \n",
              "2        3.24                  0.30             2.81             5.68  1.03   \n",
              "3        3.49                  0.24             2.18             7.80  0.86   \n",
              "4        2.69                  0.39             1.82             4.32  1.04   \n",
              "\n",
              "   od280/od315_of_diluted_wines  proline  \n",
              "0                          3.92   1065.0  \n",
              "1                          3.40   1050.0  \n",
              "2                          3.17   1185.0  \n",
              "3                          3.45   1480.0  \n",
              "4                          2.93    735.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtBpFqXcogVp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dfc24125-f406-49a0-c512-20482c40f089"
      },
      "source": [
        "set(Y_1)# we have three classes "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie_CoYneoUZ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Scaling using the Standard Scaler\n",
        "sc_1=StandardScaler()\n",
        "sc_1.fit(df_1)\n",
        "X_1=pd.DataFrame(sc_1.fit_transform(df_1))\n",
        "#train-test-split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X_1,Y_1,test_size=0.3,random_state=0)\n",
        "#Converting the dataset in proper LGB format\n",
        "d_train=lgb.Dataset(X_train, label=y_train)\n",
        "#setting up the parameters\n",
        "params={}\n",
        "params['learning_rate']=0.03\n",
        "params['boosting_type']='gbdt' #GradientBoostingDecisionTree\n",
        "params['objective']='multiclass' #Multi-class target feature\n",
        "params['metric']='multi_logloss' #metric for multi-class\n",
        "params['max_depth']=10\n",
        "params['num_class']=3 #no.of unique values in the target class not inclusive of the end value\n",
        "#training the model\n",
        "clf=lgb.train(params,d_train,100)  #training the model on 100 epocs\n",
        "#prediction on the test dataset\n",
        "y_pred_1=clf.predict(X_test)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPUrWsTHpN65",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "e5f80cec-363d-42dc-bdb2-66d43f1284c3"
      },
      "source": [
        "#printing the predictions\n",
        "y_pred_1[:10]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.95819859, 0.02205037, 0.01975104],\n",
              "       [0.05465546, 0.09575231, 0.84959223],\n",
              "       [0.20955298, 0.69498737, 0.09545964],\n",
              "       [0.95852959, 0.02096561, 0.02050481],\n",
              "       [0.04243184, 0.92053949, 0.03702867],\n",
              "       [0.43637402, 0.3875762 , 0.17604978],\n",
              "       [0.95957167, 0.01994996, 0.02047837],\n",
              "       [0.02250539, 0.05765113, 0.91984349],\n",
              "       [0.01467793, 0.97249475, 0.01282732],\n",
              "       [0.01629683, 0.93522059, 0.04848258]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQcOqEu9pYhR",
        "colab_type": "text"
      },
      "source": [
        "We can use numpy.argmax() method to print the class which has the most reasonable result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dgib4RuHpecK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#argmax() method \n",
        "y_pred_1 = [np.argmax(line) for line in y_pred_1]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H2yqQ2opeq5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88d35b62-e34c-4a1d-9441-25b2f249e6a8"
      },
      "source": [
        "y_pred_1[:10]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 2, 1, 0, 1, 0, 0, 2, 1, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc3Mv9DkpoJi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f6f24630-da44-4c72-a457-088285103bb5"
      },
      "source": [
        "precision_score(y_pred_1,y_test,average=None).mean()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9545454545454546"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DFTbTPYml2_",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q7vJykh7e9L",
        "colab_type": "text"
      },
      "source": [
        "Faster training speed and higher efficiency: Light GBM use histogram based algorithm i.e it buckets continuous feature values into discrete bins which fasten the training procedure.\n",
        "\n",
        "![alt text](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "Lower memory usage: Replaces continuous values to discrete bins which result in lower memory usage.\n",
        "\n",
        "\n",
        "Better accuracy than any other boosting algorithm: It produces much more complex trees by following leaf wise split approach rather than a level-wise approach which is the main factor in achieving higher accuracy. However, it can sometimes lead to overfitting which can be avoided by setting the max_depth parameter.\n",
        "\n",
        "\n",
        "Compatibility with Large Datasets: It is capable of performing equally good with large datasets with a significant reduction in training time as compared to XGBOOST.\n",
        "\n",
        "\n",
        "Parallel learning supported."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOi4l_LU4NQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}