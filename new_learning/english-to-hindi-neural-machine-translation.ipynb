{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport string\nfrom string import digits\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport re\n\nimport seaborn as sns\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom keras.layers import Input, LSTM, Embedding, Dense\nfrom keras.models import Model\n\nprint(os.listdir(\"../input\"))\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\npd.set_option('display.max_colwidth', -1)\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"name":"stderr","output_type":"stream","text":"Using TensorFlow backend.\n"},{"name":"stdout","output_type":"stream","text":"['Hindi_English_Truncated_Corpus.csv']\n"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"lines=pd.read_csv(\"../input/Hindi_English_Truncated_Corpus.csv\",encoding='utf-8')","execution_count":2,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"lines['source'].value_counts()","execution_count":3,"outputs":[{"data":{"text/plain":"tides        50000\nted          39881\nindic2012    37726\nName: source, dtype: int64"},"execution_count":3,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"lines=lines[lines['source']=='ted']","execution_count":4,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"lines.head(20)","execution_count":5,"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>english_sentence</th>\n      <th>hindi_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ted</td>\n      <td>politicians do not have permission to do what needs to be done.</td>\n      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह करने कि अनुमति नहीं है .</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ted</td>\n      <td>I'd like to tell you about one such child,</td>\n      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहूंगी,</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ted</td>\n      <td>what we really mean is that they're bad at not paying attention.</td>\n      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ted</td>\n      <td>And who are we to say, even, that they are wrong</td>\n      <td>और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>ted</td>\n      <td>So there is some sort of justice</td>\n      <td>तो वहाँ न्याय है</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>ted</td>\n      <td>This changed slowly</td>\n      <td>धीरे धीरे ये सब बदला</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>ted</td>\n      <td>were being produced.</td>\n      <td>उत्पन्न नहीं कि जाती थी.</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>ted</td>\n      <td>And you can see, this LED is going to glow.</td>\n      <td>और जैसा आप देख रहे है, ये एल.ई.डी. जल उठेगी।</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>ted</td>\n      <td>to turn on the lights or to bring him a glass of water,</td>\n      <td>लाईट जलाने के लिए या उनके लिए पानी लाने के लिए,</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>ted</td>\n      <td>Can you imagine saying that?</td>\n      <td>क्या आप ये कल्पना कर सकते है</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>ted</td>\n      <td>Three: this is a good road in - right near where our factory is located.</td>\n      <td>तीसरी: ये हमारी फ़ैक्ट्री के पास की एक अपेक्षाकृत बेहतर सडक है।</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>ted</td>\n      <td>What's going on?”</td>\n      <td>क्या हो रहा है ये?”</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>ted</td>\n      <td>There are also financial reforms in rural China.</td>\n      <td>ग्रामीण चीन में आर्थिक नवीनीकरण हुये हैं।</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>ted</td>\n      <td>the family planning started in Vietnam and they went for smaller families.</td>\n      <td>वियतनाम में परिवार योजना शुरू हो गई और उनके परिवार छोटे होने लगे।</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>ted</td>\n      <td>I mean, at that time, trust me,</td>\n      <td>मेरा मतलब, उस समय, सही मानिए,</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>ted</td>\n      <td>Not only that,</td>\n      <td>बस वही नहीं,</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>ted</td>\n      <td>humans destroyed the commons that they depended on.</td>\n      <td>मानवों ने उन ही साझे संसाधनों को नष्ट किया जिन पर वो आधारित थे।</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>ted</td>\n      <td>Almost goes to E, but otherwise the play would be over.</td>\n      <td>रचना करीब करीब ई तक जाती है, मगर तब तो नाटक ख़त्म हो जाएगा.</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>ted</td>\n      <td>So I want to share with you a couple key insights</td>\n      <td>मैं आपके साथ कुछ मुख्य सूत्र बाँटना चाहता हूँ</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>ted</td>\n      <td>Many countries in the [unclear], they need legitimacy.</td>\n      <td>[अस्पष्ट] के बहुत सारे राष्ट्रों को मान्यता चाहिए.</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"   source                                                            english_sentence                                                        hindi_sentence\n0   ted    politicians do not have permission to do what needs to be done.             राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह करने कि अनुमति नहीं है .\n1   ted    I'd like to tell you about one such child,                                  मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहूंगी,                  \n3   ted    what we really mean is that they're bad at not paying attention.            हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते                      \n7   ted    And who are we to say, even, that they are wrong                            और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं                    \n13  ted    So there is some sort of justice                                            तो वहाँ न्याय है                                                    \n23  ted    This changed slowly                                                         धीरे धीरे ये सब बदला                                                \n26  ted    were being produced.                                                        उत्पन्न नहीं कि जाती थी.                                            \n30  ted    And you can see, this LED is going to glow.                                 और जैसा आप देख रहे है, ये एल.ई.डी. जल उठेगी।                        \n32  ted    to turn on the lights or to bring him a glass of water,                     लाईट जलाने के लिए या उनके लिए पानी लाने के लिए,                     \n35  ted    Can you imagine saying that?                                                क्या आप ये कल्पना कर सकते है                                        \n37  ted    Three: this is a good road in - right near where our factory is located.    तीसरी: ये हमारी फ़ैक्ट्री के पास की एक अपेक्षाकृत बेहतर सडक है।     \n39  ted    What's going on?”                                                           क्या हो रहा है ये?”                                                 \n42  ted    There are also financial reforms in rural China.                            ग्रामीण चीन में आर्थिक नवीनीकरण हुये हैं।                           \n49  ted    the family planning started in Vietnam and they went for smaller families.  वियतनाम में परिवार योजना शुरू हो गई और उनके परिवार छोटे होने लगे।   \n51  ted    I mean, at that time, trust me,                                             मेरा मतलब, उस समय, सही मानिए,                                       \n53  ted    Not only that,                                                              बस वही नहीं,                                                        \n55  ted    humans destroyed the commons that they depended on.                         मानवों ने उन ही साझे संसाधनों को नष्ट किया जिन पर वो आधारित थे।     \n56  ted    Almost goes to E, but otherwise the play would be over.                     रचना करीब करीब ई तक जाती है, मगर तब तो नाटक ख़त्म हो जाएगा.         \n63  ted    So I want to share with you a couple key insights                           मैं आपके साथ कुछ मुख्य सूत्र बाँटना चाहता हूँ                       \n66  ted    Many countries in the [unclear], they need legitimacy.                      [अस्पष्ट] के बहुत सारे राष्ट्रों को मान्यता चाहिए.                  "},"execution_count":5,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"pd.isnull(lines).sum()","execution_count":6,"outputs":[{"data":{"text/plain":"source              0\nenglish_sentence    0\nhindi_sentence      0\ndtype: int64"},"execution_count":6,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"lines=lines[~pd.isnull(lines['english_sentence'])]","execution_count":7,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"lines.drop_duplicates(inplace=True)","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* ### Let us pick any 25000 rows from the dataset."},{"metadata":{"trusted":false},"cell_type":"code","source":"lines=lines.sample(n=25000,random_state=42)\nlines.shape","execution_count":9,"outputs":[{"data":{"text/plain":"(25000, 3)"},"execution_count":9,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Lowercase all characters\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: x.lower())\nlines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.lower())","execution_count":10,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Remove quotes\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\nlines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\"'\", '', x))","execution_count":11,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"exclude = set(string.punctuation) # Set of all special characters\n# Remove all the special characters\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\nlines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))","execution_count":12,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Remove all numbers from text\nremove_digits = str.maketrans('', '', digits)\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: x.translate(remove_digits))\nlines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.translate(remove_digits))\n\nlines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n\n# Remove extra spaces\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: x.strip())\nlines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.strip())\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\nlines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n","execution_count":13,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Add start and end tokens to target sequences\nlines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x : 'START_ '+ x + ' _END')","execution_count":14,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"lines.head()","execution_count":15,"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>english_sentence</th>\n      <th>hindi_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>82040</th>\n      <td>ted</td>\n      <td>we still dont know who her parents are who she is</td>\n      <td>START_ हम अभी तक नहीं जानते हैं कि उसके मातापिता कौन हैं वह कौन है _END</td>\n    </tr>\n    <tr>\n      <th>85038</th>\n      <td>ted</td>\n      <td>no keyboard</td>\n      <td>START_ कोई कुंजीपटल नहीं _END</td>\n    </tr>\n    <tr>\n      <th>58018</th>\n      <td>ted</td>\n      <td>but as far as being a performer</td>\n      <td>START_ लेकिन एक कलाकार होने के साथ _END</td>\n    </tr>\n    <tr>\n      <th>74470</th>\n      <td>ted</td>\n      <td>and this particular balloon</td>\n      <td>START_ और यह खास गुब्बारा _END</td>\n    </tr>\n    <tr>\n      <th>122330</th>\n      <td>ted</td>\n      <td>and its not as hard as you think integrate climate solutions into all of your innovations</td>\n      <td>START_ और जितना आपको लगता है यह उतना कठिन नहीं हैअपने सभी नवाचारों में जलवायु समाधान को एकीकृत करें _END</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"       source                                                                           english_sentence                                                                                            hindi_sentence\n82040   ted    we still dont know who her parents are who she is                                          START_ हम अभी तक नहीं जानते हैं कि उसके मातापिता कौन हैं वह कौन है _END                                 \n85038   ted    no keyboard                                                                                START_ कोई कुंजीपटल नहीं _END                                                                           \n58018   ted    but as far as being a performer                                                            START_ लेकिन एक कलाकार होने के साथ _END                                                                 \n74470   ted    and this particular balloon                                                                START_ और यह खास गुब्बारा _END                                                                          \n122330  ted    and its not as hard as you think integrate climate solutions into all of your innovations  START_ और जितना आपको लगता है यह उतना कठिन नहीं हैअपने सभी नवाचारों में जलवायु समाधान को एकीकृत करें _END"},"execution_count":15,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"### Get English and Hindi Vocabulary\nall_eng_words=set()\nfor eng in lines['english_sentence']:\n    for word in eng.split():\n        if word not in all_eng_words:\n            all_eng_words.add(word)\n\nall_hindi_words=set()\nfor hin in lines['hindi_sentence']:\n    for word in hin.split():\n        if word not in all_hindi_words:\n            all_hindi_words.add(word)","execution_count":16,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"len(all_eng_words)","execution_count":17,"outputs":[{"data":{"text/plain":"14030"},"execution_count":17,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"len(all_hindi_words)","execution_count":18,"outputs":[{"data":{"text/plain":"17540"},"execution_count":18,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"lines['length_eng_sentence']=lines['english_sentence'].apply(lambda x:len(x.split(\" \")))\nlines['length_hin_sentence']=lines['hindi_sentence'].apply(lambda x:len(x.split(\" \")))","execution_count":19,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"lines.head()","execution_count":20,"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>english_sentence</th>\n      <th>hindi_sentence</th>\n      <th>length_eng_sentence</th>\n      <th>length_hin_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>82040</th>\n      <td>ted</td>\n      <td>we still dont know who her parents are who she is</td>\n      <td>START_ हम अभी तक नहीं जानते हैं कि उसके मातापिता कौन हैं वह कौन है _END</td>\n      <td>11</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>85038</th>\n      <td>ted</td>\n      <td>no keyboard</td>\n      <td>START_ कोई कुंजीपटल नहीं _END</td>\n      <td>2</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>58018</th>\n      <td>ted</td>\n      <td>but as far as being a performer</td>\n      <td>START_ लेकिन एक कलाकार होने के साथ _END</td>\n      <td>7</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>74470</th>\n      <td>ted</td>\n      <td>and this particular balloon</td>\n      <td>START_ और यह खास गुब्बारा _END</td>\n      <td>4</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>122330</th>\n      <td>ted</td>\n      <td>and its not as hard as you think integrate climate solutions into all of your innovations</td>\n      <td>START_ और जितना आपको लगता है यह उतना कठिन नहीं हैअपने सभी नवाचारों में जलवायु समाधान को एकीकृत करें _END</td>\n      <td>16</td>\n      <td>20</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"       source                                                                           english_sentence                                                                                            hindi_sentence  length_eng_sentence  length_hin_sentence\n82040   ted    we still dont know who her parents are who she is                                          START_ हम अभी तक नहीं जानते हैं कि उसके मातापिता कौन हैं वह कौन है _END                                   11                   16                 \n85038   ted    no keyboard                                                                                START_ कोई कुंजीपटल नहीं _END                                                                             2                    5                  \n58018   ted    but as far as being a performer                                                            START_ लेकिन एक कलाकार होने के साथ _END                                                                   7                    8                  \n74470   ted    and this particular balloon                                                                START_ और यह खास गुब्बारा _END                                                                            4                    6                  \n122330  ted    and its not as hard as you think integrate climate solutions into all of your innovations  START_ और जितना आपको लगता है यह उतना कठिन नहीं हैअपने सभी नवाचारों में जलवायु समाधान को एकीकृत करें _END  16                   20                 "},"execution_count":20,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"lines[lines['length_eng_sentence']>30].shape","execution_count":21,"outputs":[{"data":{"text/plain":"(0, 5)"},"execution_count":21,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"lines=lines[lines['length_eng_sentence']<=20]\nlines=lines[lines['length_hin_sentence']<=20]","execution_count":22,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"lines.shape","execution_count":23,"outputs":[{"data":{"text/plain":"(24774, 5)"},"execution_count":23,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(\"maximum length of Hindi Sentence \",max(lines['length_hin_sentence']))\nprint(\"maximum length of English Sentence \",max(lines['length_eng_sentence']))","execution_count":24,"outputs":[{"name":"stdout","output_type":"stream","text":"maximum length of Hindi Sentence  20\nmaximum length of English Sentence  20\n"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"max_length_src=max(lines['length_hin_sentence'])\nmax_length_tar=max(lines['length_eng_sentence'])","execution_count":25,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"input_words = sorted(list(all_eng_words))\ntarget_words = sorted(list(all_hindi_words))\nnum_encoder_tokens = len(all_eng_words)\nnum_decoder_tokens = len(all_hindi_words)\nnum_encoder_tokens, num_decoder_tokens","execution_count":26,"outputs":[{"data":{"text/plain":"(14030, 17540)"},"execution_count":26,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"num_decoder_tokens += 1 #for zero padding\n","execution_count":27,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\ntarget_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])","execution_count":28,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\nreverse_target_char_index = dict((i, word) for word, i in target_token_index.items())","execution_count":29,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"lines = shuffle(lines)\nlines.head(10)","execution_count":30,"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>english_sentence</th>\n      <th>hindi_sentence</th>\n      <th>length_eng_sentence</th>\n      <th>length_hin_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>124307</th>\n      <td>ted</td>\n      <td>the boston shuffler the carnival</td>\n      <td>START_ बोस्टनपैरघसीटनेवाला “कार्निवल” _END</td>\n      <td>5</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>17340</th>\n      <td>ted</td>\n      <td>in the villages in the slums</td>\n      <td>START_ गाँवों और झुग्गियों से _END</td>\n      <td>6</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>74027</th>\n      <td>ted</td>\n      <td>we created competition for ourselves</td>\n      <td>START_ हमने खुद अपने लिये चुनौतियाँ खडी कीं _END</td>\n      <td>5</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>56767</th>\n      <td>ted</td>\n      <td>for good and for ill</td>\n      <td>START_ अच्छे के लिए और बुरे के लिए _END</td>\n      <td>5</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>28653</th>\n      <td>ted</td>\n      <td>and when you ask people about connection</td>\n      <td>START_ और जब आप लोगों से संपर्क के बारे में पूछते हैं _END</td>\n      <td>7</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>83421</th>\n      <td>ted</td>\n      <td>meanwhile my friends were working for five hours</td>\n      <td>START_ जबकि मेरे दोस्त पाँच घण्टों तक काम करके _END</td>\n      <td>8</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>94491</th>\n      <td>ted</td>\n      <td>the perverse at heart</td>\n      <td>START_ पंकिल हृदय वाले _END</td>\n      <td>4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>13751</th>\n      <td>ted</td>\n      <td>where great images of mother goddesses are built</td>\n      <td>START_ देवियों की महान मूर्तियाँ तैयार की जाती हैं _END</td>\n      <td>8</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>28563</th>\n      <td>ted</td>\n      <td>and it killed people</td>\n      <td>START_ और लोग मरे गए _END</td>\n      <td>4</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>56845</th>\n      <td>ted</td>\n      <td>“no mama you got to look”</td>\n      <td>START_ “नहीं मामा यह तो आपको देखना ही पड़ेगा” _END</td>\n      <td>6</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"       source                                  english_sentence                                              hindi_sentence  length_eng_sentence  length_hin_sentence\n124307  ted    the boston shuffler the carnival                  START_ बोस्टनपैरघसीटनेवाला “कार्निवल” _END                  5                    4                  \n17340   ted    in the villages in the slums                      START_ गाँवों और झुग्गियों से _END                          6                    6                  \n74027   ted    we created competition for ourselves              START_ हमने खुद अपने लिये चुनौतियाँ खडी कीं _END            5                    9                  \n56767   ted    for good and for ill                              START_ अच्छे के लिए और बुरे के लिए _END                     5                    9                  \n28653   ted    and when you ask people about connection          START_ और जब आप लोगों से संपर्क के बारे में पूछते हैं _END  7                    13                 \n83421   ted    meanwhile my friends were working for five hours  START_ जबकि मेरे दोस्त पाँच घण्टों तक काम करके _END         8                    10                 \n94491   ted    the perverse at heart                             START_ पंकिल हृदय वाले _END                                 4                    5                  \n13751   ted    where great images of mother goddesses are built  START_ देवियों की महान मूर्तियाँ तैयार की जाती हैं _END     8                    10                 \n28563   ted    and it killed people                              START_ और लोग मरे गए _END                                   4                    6                  \n56845   ted    “no mama you got to look”                         START_ “नहीं मामा यह तो आपको देखना ही पड़ेगा” _END          6                    10                 "},"execution_count":30,"metadata":{},"output_type":"execute_result"}]},{"metadata":{},"cell_type":"markdown","source":"### Split the data into train and test"},{"metadata":{"trusted":false},"cell_type":"code","source":"X, y = lines['english_sentence'], lines['hindi_sentence']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42)\nX_train.shape, X_test.shape","execution_count":31,"outputs":[{"data":{"text/plain":"((19819,), (4955,))"},"execution_count":31,"metadata":{},"output_type":"execute_result"}]},{"metadata":{},"cell_type":"markdown","source":"### Let us save this data"},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train.to_pickle('X_train.pkl')\nX_test.to_pickle('X_test.pkl')\n","execution_count":32,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def generate_batch(X = X_train, y = y_train, batch_size = 128):\n    ''' Generate a batch of data '''\n    while True:\n        for j in range(0, len(X), batch_size):\n            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n                for t, word in enumerate(input_text.split()):\n                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n                for t, word in enumerate(target_text.split()):\n                    if t<len(target_text.split())-1:\n                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n                    if t>0:\n                        # decoder target sequence (one hot encoded)\n                        # does not include the START_ token\n                        # Offset by one timestep\n                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n            yield([encoder_input_data, decoder_input_data], decoder_target_data)","execution_count":33,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Encoder-Decoder Architecture"},{"metadata":{"trusted":false},"cell_type":"code","source":"latent_dim=300","execution_count":34,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Encoder\nencoder_inputs = Input(shape=(None,))\nenc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\nencoder_lstm = LSTM(latent_dim, return_state=True)\nencoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n# We discard `encoder_outputs` and only keep the states.\nencoder_states = [state_h, state_c]","execution_count":35,"outputs":[{"name":"stdout","output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Set up the decoder, using `encoder_states` as initial state.\ndecoder_inputs = Input(shape=(None,))\ndec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\ndec_emb = dec_emb_layer(decoder_inputs)\n# We set up our decoder to return full output sequences,\n# and to return internal states as well. We don't use the\n# return states in the training model, but we will use them in inference.\ndecoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\ndecoder_outputs, _, _ = decoder_lstm(dec_emb,\n                                     initial_state=encoder_states)\ndecoder_dense = Dense(num_decoder_tokens, activation='softmax')\ndecoder_outputs = decoder_dense(decoder_outputs)\n\n# Define the model that will turn\n# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs)","execution_count":36,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model.compile(optimizer='rmsprop', loss='categorical_crossentropy')","execution_count":37,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model.summary()","execution_count":38,"outputs":[{"name":"stdout","output_type":"stream","text":"__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, None)         0                                            \n__________________________________________________________________________________________________\ninput_2 (InputLayer)            (None, None)         0                                            \n__________________________________________________________________________________________________\nembedding_1 (Embedding)         (None, None, 300)    4209000     input_1[0][0]                    \n__________________________________________________________________________________________________\nembedding_2 (Embedding)         (None, None, 300)    5262300     input_2[0][0]                    \n__________________________________________________________________________________________________\nlstm_1 (LSTM)                   [(None, 300), (None, 721200      embedding_1[0][0]                \n__________________________________________________________________________________________________\nlstm_2 (LSTM)                   [(None, None, 300),  721200      embedding_2[0][0]                \n                                                                 lstm_1[0][1]                     \n                                                                 lstm_1[0][2]                     \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, None, 17541)  5279841     lstm_2[0][0]                     \n==================================================================================================\nTotal params: 16,193,541\nTrainable params: 16,193,541\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_samples = len(X_train)\nval_samples = len(X_test)\nbatch_size = 128\nepochs = 100","execution_count":39,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n                    steps_per_epoch = train_samples//batch_size,\n                    epochs=epochs,\n                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n                    validation_steps = val_samples//batch_size)\n\n","execution_count":40,"outputs":[{"name":"stdout","output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nDeprecated in favor of operator or tf.math.divide.\nEpoch 1/100\n154/154 [==============================] - 61s 398ms/step - loss: 6.4302 - val_loss: 6.1065\nEpoch 2/100\n154/154 [==============================] - 58s 379ms/step - loss: 5.8324 - val_loss: 5.7596\nEpoch 3/100\n154/154 [==============================] - 58s 375ms/step - loss: 5.4743 - val_loss: 5.5979\nEpoch 4/100\n154/154 [==============================] - 58s 374ms/step - loss: 5.2358 - val_loss: 5.4984\nEpoch 5/100\n154/154 [==============================] - 57s 371ms/step - loss: 5.0351 - val_loss: 5.4325\nEpoch 6/100\n154/154 [==============================] - 58s 374ms/step - loss: 4.8545 - val_loss: 5.3787\nEpoch 7/100\n154/154 [==============================] - 58s 374ms/step - loss: 4.6826 - val_loss: 5.3234\nEpoch 8/100\n154/154 [==============================] - 58s 376ms/step - loss: 4.5184 - val_loss: 5.3026\nEpoch 9/100\n154/154 [==============================] - 58s 374ms/step - loss: 4.3628 - val_loss: 5.2641\nEpoch 10/100\n154/154 [==============================] - 57s 371ms/step - loss: 4.2178 - val_loss: 5.2576\nEpoch 11/100\n154/154 [==============================] - 58s 374ms/step - loss: 4.0761 - val_loss: 5.2603\nEpoch 12/100\n154/154 [==============================] - 58s 373ms/step - loss: 3.9363 - val_loss: 5.2638\nEpoch 13/100\n154/154 [==============================] - 57s 372ms/step - loss: 3.8022 - val_loss: 5.2500\nEpoch 14/100\n154/154 [==============================] - 57s 371ms/step - loss: 3.6704 - val_loss: 5.2799\nEpoch 15/100\n154/154 [==============================] - 57s 371ms/step - loss: 3.5421 - val_loss: 5.2825\nEpoch 16/100\n154/154 [==============================] - 57s 368ms/step - loss: 3.4159 - val_loss: 5.3089\nEpoch 17/100\n154/154 [==============================] - 57s 369ms/step - loss: 3.2925 - val_loss: 5.3458\nEpoch 18/100\n154/154 [==============================] - 57s 369ms/step - loss: 3.1718 - val_loss: 5.3797\nEpoch 19/100\n154/154 [==============================] - 57s 369ms/step - loss: 3.0532 - val_loss: 5.4118\nEpoch 20/100\n154/154 [==============================] - 57s 369ms/step - loss: 2.9372 - val_loss: 5.4372\nEpoch 21/100\n154/154 [==============================] - 56s 365ms/step - loss: 2.8211 - val_loss: 5.4900\nEpoch 22/100\n154/154 [==============================] - 57s 368ms/step - loss: 2.7083 - val_loss: 5.5372\nEpoch 23/100\n154/154 [==============================] - 56s 366ms/step - loss: 2.5940 - val_loss: 5.5821\nEpoch 24/100\n154/154 [==============================] - 57s 367ms/step - loss: 2.4886 - val_loss: 5.6247\nEpoch 25/100\n154/154 [==============================] - 56s 367ms/step - loss: 2.3871 - val_loss: 5.6674\nEpoch 26/100\n154/154 [==============================] - 56s 365ms/step - loss: 2.2865 - val_loss: 5.7193\nEpoch 27/100\n154/154 [==============================] - 56s 367ms/step - loss: 2.1875 - val_loss: 5.7680\nEpoch 28/100\n154/154 [==============================] - 56s 366ms/step - loss: 2.0926 - val_loss: 5.7977\nEpoch 29/100\n154/154 [==============================] - 56s 365ms/step - loss: 2.0025 - val_loss: 5.8524\nEpoch 30/100\n154/154 [==============================] - 56s 366ms/step - loss: 1.9112 - val_loss: 5.8916\nEpoch 31/100\n154/154 [==============================] - 56s 365ms/step - loss: 1.8234 - val_loss: 5.9485\nEpoch 32/100\n154/154 [==============================] - 56s 365ms/step - loss: 1.7395 - val_loss: 5.9946\nEpoch 33/100\n154/154 [==============================] - 56s 364ms/step - loss: 1.6597 - val_loss: 6.0302\nEpoch 34/100\n154/154 [==============================] - 56s 364ms/step - loss: 1.5847 - val_loss: 6.1043\nEpoch 35/100\n154/154 [==============================] - 56s 364ms/step - loss: 1.5099 - val_loss: 6.1382\nEpoch 36/100\n154/154 [==============================] - 56s 363ms/step - loss: 1.4439 - val_loss: 6.1812\nEpoch 37/100\n154/154 [==============================] - 57s 370ms/step - loss: 1.3744 - val_loss: 6.2156\nEpoch 38/100\n154/154 [==============================] - 57s 371ms/step - loss: 1.3123 - val_loss: 6.2601\nEpoch 39/100\n154/154 [==============================] - 57s 369ms/step - loss: 1.2487 - val_loss: 6.3008\nEpoch 40/100\n154/154 [==============================] - 60s 388ms/step - loss: 1.1887 - val_loss: 6.3586\nEpoch 41/100\n154/154 [==============================] - 57s 370ms/step - loss: 1.1322 - val_loss: 6.4005\nEpoch 42/100\n  2/154 [..............................] - ETA: 46s - loss: 1.1351"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"model.save_weights('nmt_weights.h5')","execution_count":41,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Encode the input sequence to get the \"thought vectors\"\nencoder_model = Model(encoder_inputs, encoder_states)\n\n# Decoder setup\n# Below tensors will hold the states of the previous time step\ndecoder_state_input_h = Input(shape=(latent_dim,))\ndecoder_state_input_c = Input(shape=(latent_dim,))\ndecoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n\ndec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n\n# To predict the next word in the sequence, set the initial states to the states from the previous time step\ndecoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\ndecoder_states2 = [state_h2, state_c2]\ndecoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n\n# Final decoder model\ndecoder_model = Model(\n    [decoder_inputs] + decoder_states_inputs,\n    [decoder_outputs2] + decoder_states2)\n","execution_count":42,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def decode_sequence(input_seq):\n    # Encode the input as state vectors.\n    states_value = encoder_model.predict(input_seq)\n    # Generate empty target sequence of length 1.\n    target_seq = np.zeros((1,1))\n    # Populate the first character of target sequence with the start character.\n    target_seq[0, 0] = target_token_index['START_']\n\n    # Sampling loop for a batch of sequences\n    # (to simplify, here we assume a batch of size 1).\n    stop_condition = False\n    decoded_sentence = ''\n    while not stop_condition:\n        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n\n        # Sample a token\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_char = reverse_target_char_index[sampled_token_index]\n        decoded_sentence += ' '+sampled_char\n\n        # Exit condition: either hit max length\n        # or find stop character.\n        if (sampled_char == '_END' or\n           len(decoded_sentence) > 50):\n            stop_condition = True\n\n        # Update the target sequence (of length 1).\n        target_seq = np.zeros((1,1))\n        target_seq[0, 0] = sampled_token_index\n\n        # Update states\n        states_value = [h, c]\n\n    return decoded_sentence","execution_count":43,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_gen = generate_batch(X_train, y_train, batch_size = 1)\nk=-1\n","execution_count":44,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"k+=1\n(input_seq, actual_output), _ = next(train_gen)\ndecoded_sentence = decode_sequence(input_seq)\nprint('Input English sentence:', X_train[k:k+1].values[0])\nprint('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\nprint('Predicted Hindi Translation:', decoded_sentence[:-4])","execution_count":45,"outputs":[{"name":"stdout","output_type":"stream","text":"Input English sentence: in order to understand whether this is true\nActual Hindi Translation:  यह समझने के लिए कि क्या यह सच है \nPredicted Hindi Translation:  यह समझने के लिए कि क्या यह सच है \n"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"k+=1\n(input_seq, actual_output), _ = next(train_gen)\ndecoded_sentence = decode_sequence(input_seq)\nprint('Input English sentence:', X_train[k:k+1].values[0])\nprint('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\nprint('Predicted Hindi Translation:', decoded_sentence[:-4])","execution_count":46,"outputs":[{"name":"stdout","output_type":"stream","text":"Input English sentence: to why india is today growing\nActual Hindi Translation:  कि भारत आज आगे बढ़ रहा है \nPredicted Hindi Translation:  कि भारत आज आगे बढ़ रहा है \n"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"k+=1\n(input_seq, actual_output), _ = next(train_gen)\ndecoded_sentence = decode_sequence(input_seq)\nprint('Input English sentence:', X_train[k:k+1].values[0])\nprint('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\nprint('Predicted Hindi Translation:', decoded_sentence[:-4])","execution_count":47,"outputs":[{"name":"stdout","output_type":"stream","text":"Input English sentence: then theyll live years longer”\nActual Hindi Translation:  तो वे साल अधिक जियेंगे” \nPredicted Hindi Translation:  तो वे साल अधिक जियेंगे” \n"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"k+=1\n(input_seq, actual_output), _ = next(train_gen)\ndecoded_sentence = decode_sequence(input_seq)\nprint('Input English sentence:', X_train[k:k+1].values[0])\nprint('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\nprint('Predicted Hindi Translation:', decoded_sentence[:-4])","execution_count":48,"outputs":[{"name":"stdout","output_type":"stream","text":"Input English sentence: and start thinking about the long long line from b to e\nActual Hindi Translation:  और सोचना होता है उस लम्बी लम्बी रेखा के बारे में जो बी से ई तक जाती है \nPredicted Hindi Translation:  और सोचना होता है और पता चला रहा है \n"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"k+=1\n(input_seq, actual_output), _ = next(train_gen)\ndecoded_sentence = decode_sequence(input_seq)\nprint('Input English sentence:', X_train[k:k+1].values[0])\nprint('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\nprint('Predicted Hindi Translation:', decoded_sentence[:-4])","execution_count":49,"outputs":[{"name":"stdout","output_type":"stream","text":"Input English sentence: well have a model for the rest of language\nActual Hindi Translation:  हमारे पास बाकि भषा के लिए मापद्न्ड होगा \nPredicted Hindi Translation:  तो हमारे पास अच्छी माँ का उपयोग हो सकता है \n"}]},{"metadata":{},"cell_type":"markdown","source":"Reference: \n\n1. https://arxiv.org/pdf/1409.3215.pdf\n2. https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html\n3. https://towardsdatascience.com/word-level-english-to-marathi-neural-machine-translation-using-seq2seq-encoder-decoder-lstm-model-1a913f2dc4a7\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}