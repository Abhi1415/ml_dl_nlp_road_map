{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.0 lemmatization .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUAtrHwcXA6S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "c49cfd71-6c0b-4360-a62d-33b9e5076674"
      },
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer,SnowballStemmer,WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGmSRJ76XwCt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27a9f351-a0d5-4aaa-a2f6-8569ef09c911"
      },
      "source": [
        "stopwords.words('english')[:10]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agnMnl25iiXB",
        "colab_type": "text"
      },
      "source": [
        "**OverStemming**\n",
        "\n",
        "Over-stemming is when two words with different stems are stemmed to the same root. This is also known as a false positive.\n",
        "\n",
        "universal\n",
        "\n",
        "university\n",
        "\n",
        "universe\n",
        "\n",
        "All the above 3 words are stemmed to univers which is wrong behavior.\n",
        "Though these three words are etymologically related, their modern meanings are in widely different domains, so treating them as synonyms in NLP/NLU will likely reduce the relevance of the search results\n",
        "\n",
        "**UnderStemming**\n",
        "\n",
        "Under-stemming is when two words that should be stemmed to the same root are not. This is also known as a false negative. Below is the example for the same.\n",
        "\n",
        "alumnus\n",
        "\n",
        "alumni\n",
        "\n",
        "alumnae"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J_QLdRWjQYU",
        "colab_type": "text"
      },
      "source": [
        "**1.  Wordnet Lemmatizer with NLTK**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmVsv6VjYysp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "paragraph = \"\"\"Thank you all so very much. Thank you to the Academy. \n",
        "               Thank you to all of you in this room. I have to congratulate \n",
        "               the other incredible nominees this year. The Revenant was \n",
        "               the product of the tireless efforts of an unbelievable cast\n",
        "               and crew. First off, to my brother in this endeavor, Mr. Tom \n",
        "               Hardy. Tom, your talent on screen can only be surpassed by \n",
        "               your friendship off screen … thank you for creating a t\n",
        "               ranscendent cinematic experience. Thank you to everybody at \n",
        "               Fox and New Regency … my entire team. I have to thank \n",
        "               everyone from the very onset of my career … To my parents; \n",
        "               none of this would be possible without you. And to my \n",
        "               friends, I love you dearly; you know who you are. And lastly,\n",
        "               I just want to say this: Making The Revenant was about\n",
        "               man's relationship to the natural world. A world that we\n",
        "               collectively felt in 2015 as the hottest year in recorded\n",
        "               history. Our production needed to move to the southern\n",
        "               tip of this planet just to be able to find snow. Climate\n",
        "               change is real, it is happening right now. It is the most\n",
        "               urgent threat facing our entire species, and we need to work\n",
        "               collectively together and stop procrastinating. We need to\n",
        "               support leaders around the world who do not speak for the \n",
        "               big polluters, but who speak for all of humanity, for the\n",
        "               indigenous people of the world, for the billions and \n",
        "               billions of underprivileged people out there who would be\n",
        "               most affected by this. For our children’s children, and \n",
        "               for those people out there whose voices have been drowned\n",
        "               out by the politics of greed. I thank you all for this \n",
        "               amazing award tonight. Let us not take this planet for \n",
        "               granted. I do not take tonight for granted. Thank you so very much.\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJJPgYmfaKCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = nltk.sent_tokenize(paragraph)\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Lemmatization\n",
        "for i in range(len(sentences)):\n",
        "    words = nltk.word_tokenize(sentences[i])\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
        "    sentences[i] = ' '.join(words)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AI-5r35XaMXU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "946503df-cf7e-474e-f96a-6baee2463c4f"
      },
      "source": [
        "sentences"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Thank much .',\n",
              " 'Thank Academy .',\n",
              " 'Thank room .',\n",
              " 'I congratulate incredible nominee year .',\n",
              " 'The Revenant product tireless effort unbelievable cast crew .',\n",
              " 'First , brother endeavor , Mr. Tom Hardy .',\n",
              " 'Tom , talent screen surpassed friendship screen … thank creating ranscendent cinematic experience .',\n",
              " 'Thank everybody Fox New Regency … entire team .',\n",
              " 'I thank everyone onset career … To parent ; none would possible without .',\n",
              " 'And friend , I love dearly ; know .',\n",
              " \"And lastly , I want say : Making The Revenant man 's relationship natural world .\",\n",
              " 'A world collectively felt 2015 hottest year recorded history .',\n",
              " 'Our production needed move southern tip planet able find snow .',\n",
              " 'Climate change real , happening right .',\n",
              " 'It urgent threat facing entire specie , need work collectively together stop procrastinating .',\n",
              " 'We need support leader around world speak big polluter , speak humanity , indigenous people world , billion billion underprivileged people would affected .',\n",
              " 'For child ’ child , people whose voice drowned politics greed .',\n",
              " 'I thank amazing award tonight .',\n",
              " 'Let u take planet granted .',\n",
              " 'I take tonight granted .',\n",
              " 'Thank much .']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjaXdsz2aZiQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s = '\"The striped bats are hanging on their feet for best\"'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZyKPShPZzNu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f3f631d3-acbe-417a-8edc-cae447e77cdb"
      },
      "source": [
        "# Tokenize: Split the sentence into words\n",
        "word_list = nltk.word_tokenize(s)\n",
        "print(word_list)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['``', 'The', 'striped', 'bats', 'are', 'hanging', 'on', 'their', 'feet', 'for', 'best', \"''\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Spx-u79eltJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lemmatize list of words and join\n",
        "lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNcvoZfklvff",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1780b7c5-dcd4-4861-9fc2-22286f93281c"
      },
      "source": [
        "print(lemmatized_output)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`` The striped bat are hanging on their foot for best ''\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M25x7SZIl8-X",
        "colab_type": "text"
      },
      "source": [
        "it didn’t do a good job. Because, ‘are’ is not converted to ‘be’ and ‘hanging’ is not converted to ‘hang’ as expected. This can be corrected if we provide the correct ‘part-of-speech’ tag (POS tag) as the second argument to lemmatize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZfF-1aqnja2",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**2. Wordnet Lemmatizer with appropriate POS tag**\n",
        "\n",
        "#https://www.nltk.org/book/ch05.html\n",
        "part-of-speech tagger, or POS-tagger, processes a sequence of words, and attaches a part of speech tag to each word "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF94RGVHnzoB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "9c369210-0aa2-432c-bfc5-82accdb80873"
      },
      "source": [
        "text = word_tokenize(\"And now for something completely different\")\n",
        "nltk.pos_tag(text)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('And', 'CC'),\n",
              " ('now', 'RB'),\n",
              " ('for', 'IN'),\n",
              " ('something', 'NN'),\n",
              " ('completely', 'RB'),\n",
              " ('different', 'JJ')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAsACmZSoCZS",
        "colab_type": "text"
      },
      "source": [
        "Here we see that and is CC, a coordinating conjunction; now and completely are RB, or adverbs; for is IN, a preposition; something is NN, a noun; and different is JJ, an adjective"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGcPh_GXo0j1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word='feet'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFjqFWSmoEka",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d0b03bf-f89d-414f-89bb-eb3855769b6c"
      },
      "source": [
        "tag = nltk.pos_tag([word])\n",
        "tag"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('feet', 'NNS')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4jnCICTqImx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "86327b6f-d981-48b9-e902-3cead3fdfa46"
      },
      "source": [
        "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\")) \n",
        "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\"))  \n",
        "# a denotes adjective in \"pos\" \n",
        "print(\"better :\", lemmatizer.lemmatize(\"better\", pos =\"a\")) "
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rocks : rock\n",
            "corpora : corpus\n",
            "better : good\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vh5LUR99pOml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lemmatize with POS Tag\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "def get_wordnet_pos(word):\n",
        "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "\n",
        "    return tag_dict.get(tag, wordnet.NOUN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pizxfwKrpTuw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. Init Lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imyahzGrpWpB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc432e24-80b3-434d-c34e-71bf9b8049d3"
      },
      "source": [
        "# 2. Lemmatize Single Word with the appropriate POS tag\n",
        "word = 'feet'\n",
        "print(lemmatizer.lemmatize(word, get_wordnet_pos(word)))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "foot\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y8VnRN4pZuU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d062eb7e-6138-4edb-87e3-806ad80fe897"
      },
      "source": [
        "# 3. Lemmatize a Sentence with the appropriate POS tag\n",
        "sentence = \"The striped bats are hanging on their feet for best\"\n",
        "print([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(sentence)])"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The', 'strip', 'bat', 'be', 'hang', 'on', 'their', 'foot', 'for', 'best']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aW_OXaw9qhig",
        "colab_type": "text"
      },
      "source": [
        "**3. spaCy Lemmatization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbcMMCtnqkeb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "\n",
        "# Initialize spacy 'en' model, keeping only tagger component needed for lemmatization\n",
        "nlp = spacy.load('en', disable=['parser', 'ner'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKGpNEihqk0t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e82662b-a6a9-4210-9d5b-ce719a8d10e9"
      },
      "source": [
        "sentence = \"The striped bats are hanging on their feet for best\"\n",
        "# Parse the sentence using the loaded 'en' model object `nlp`\n",
        "doc = nlp(sentence)\n",
        "doc"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "The striped bats are hanging on their feet for best"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96B5_NmHqlIc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9861d10-538a-4f8b-cb49-44f40a74b0ac"
      },
      "source": [
        "# Extract the lemma for each token and join\n",
        "\" \".join([token.lemma_ for token in doc])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the stripe bat be hang on -PRON- foot for good'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfcOGdBzrV2k",
        "colab_type": "text"
      },
      "source": [
        "It did all the lemmatizations the Wordnet Lemmatizer supplied with the correct POS tag did. Plus it also lemmatized ‘best’ to ‘good’. Nice!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dECoi36nrZHW",
        "colab_type": "text"
      },
      "source": [
        "**4.TextBlob Lemmatizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qm6_koskrkcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from textblob import TextBlob, Word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOLgoeSIrlIO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8bcf07aa-3c1e-4dd4-e1c3-74cecfe177ee"
      },
      "source": [
        "# Lemmatize a word\n",
        "word = 'stripes'\n",
        "w = Word(word)\n",
        "w"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'stripes'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2yYjT-BrlDD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c08379d5-3ff2-455c-acb1-699224d3bd72"
      },
      "source": [
        "w.lemmatize()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'stripe'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPA9Q0Sark97",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e98c8410-2628-43a5-e78b-0a7641c416e9"
      },
      "source": [
        "# Lemmatize a sentence\n",
        "sentence = \"The striped bats are hanging on their feet for best\"\n",
        "sent = TextBlob(sentence)\n",
        "\" \". join([w.lemmatize() for w in sent.words])"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The striped bat are hanging on their foot for best'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mIr0zxhsCxP",
        "colab_type": "text"
      },
      "source": [
        "**5. TextBlob Lemmatizer with appropriate POS tag**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jArgY2n1rk04",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "644e6bd3-083b-44bb-8fed-837043c73c88"
      },
      "source": [
        "# Define function to lemmatize each word with its POS tag\n",
        "def lemmatize_with_postag(sentence):\n",
        "    sent = TextBlob(sentence)\n",
        "    tag_dict = {\"J\": 'a', \n",
        "                \"N\": 'n', \n",
        "                \"V\": 'v', \n",
        "                \"R\": 'r'}\n",
        "    words_and_tags = [(w, tag_dict.get(pos[0], 'n')) for w, pos in sent.tags]    \n",
        "    lemmatized_list = [wd.lemmatize(tag) for wd, tag in words_and_tags]\n",
        "    return \" \".join(lemmatized_list)\n",
        "\n",
        "# Lemmatize\n",
        "sentence = \"The striped bats are hanging on their feet for best\"\n",
        "lemmatize_with_postag(sentence)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The striped bat be hang on their foot for best'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BIkjk-vuR_W",
        "colab_type": "text"
      },
      "source": [
        "**Comparing NLTK, TextBlob, spaCy, Pattern and Stanford CoreNLP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DW8hQuY6uZdm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = \"\"\"Following mice attacks, caring farmers were marching to Delhi for better living conditions. \n",
        "Delhi police on Tuesday fired water cannons and teargas shells at protesting farmers as they tried to \n",
        "break barricades with their cars, automobiles and tractors.\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRiL2hlUx6FW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "66d0af63-582d-4a85-c3ff-f099ad99ab75"
      },
      "source": [
        "string.punctuation"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTUhhTCcugqQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4aaa87bf-fdd1-49e0-dccc-3ccf6967ca2e"
      },
      "source": [
        "# NLTK\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "print(\" \".join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(sentence) if w not in string.punctuation]))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Following mouse attack care farmer be march to Delhi for well living condition Delhi police on Tuesday fire water cannon and teargas shell at protest farmer a they try to break barricade with their car automobile and tractor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a6nlSwgyIKM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8a64b2ef-b89f-4f7a-bc5c-93adf7acc59c"
      },
      "source": [
        "# Spacy\n",
        "import spacy\n",
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "doc = nlp(sentence)\n",
        "print(\" \".join([token.lemma_ for token in doc]))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "follow mice attack , care farmer be march to Delhi for well living condition . \n",
            " Delhi police on Tuesday fire water cannon and teargas shell at protest farmer as -PRON- try to \n",
            " break barricade with -PRON- car , automobile and tractor .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4NFL79TyTvD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "91daa9a6-01e4-4904-89ba-08d876ef9757"
      },
      "source": [
        "# TextBlob\n",
        "print(lemmatize_with_postag(sentence))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Following mouse attack care farmer be march to Delhi for good living condition Delhi police on Tuesday fire water cannon and teargas shell at protest farmer a they try to break barricade with their car automobile and tractor\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}