{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word_embedding_using_keras.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx-zGfMleo87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_7Yjv5Oibyt",
        "colab_type": "text"
      },
      "source": [
        "A word embedding is a class of approaches for representing words and documents using a dense vector representation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMJehqAteprT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8db90f83-e25a-4c55-bb6d-bc41bf160129"
      },
      "source": [
        "# data visualisation and manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import seaborn as sns\n",
        "#configure\n",
        "# sets matplotlib to inline and displays graphs below the corressponding cell.\n",
        "%matplotlib inline  \n",
        "style.use('fivethirtyeight')\n",
        "sns.set(style='whitegrid',color_codes=True)\n",
        "\n",
        "#nltk\n",
        "import nltk\n",
        "\n",
        "#stop-words\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# tokenizing\n",
        "from nltk import word_tokenize,sent_tokenize"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kH0eVjPep-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##tensorflow >2.0\n",
        "from tensorflow.keras.preprocessing.text import one_hot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JR99VLD0eqMu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "ad8da872-72c6-4f34-e3f3-d0b9ea8dac83"
      },
      "source": [
        "### sentences\n",
        "sent=[  'the glass of milk',\n",
        "     'the glass of juice',\n",
        "     'the cup of tea',\n",
        "    'I am a good boy',\n",
        "     'I am a good developer',\n",
        "     'understand the meaning of words',\n",
        "     'your videos are good',]\n",
        "sent"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the glass of milk',\n",
              " 'the glass of juice',\n",
              " 'the cup of tea',\n",
              " 'I am a good boy',\n",
              " 'I am a good developer',\n",
              " 'understand the meaning of words',\n",
              " 'your videos are good']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXDWs7zvjwaH",
        "colab_type": "text"
      },
      "source": [
        "**INTEGER ENCODING ALL THE DOCUMENTS**\n",
        "\n",
        "After this all the unique words will be reprsented by an integer. For this we are using one_hot function from the Keras. Note that the vocab_size is specified large enough so as to ensure unique integer encoding for each and every word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtebkE9CjYF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#vocab size\n",
        "voc_size=50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Edejex4EjYas",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7902ca25-9461-4865-bd01-138fce99dfb5"
      },
      "source": [
        "onehot_repr=[one_hot(words,voc_size)for words in sent] \n",
        "print(onehot_repr)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10, 33, 48, 17], [10, 33, 48, 46], [10, 48, 48, 43], [21, 39, 16, 5, 46], [21, 39, 16, 5, 37], [37, 10, 41, 48, 31], [13, 11, 29, 5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVwrCaBekMUR",
        "colab_type": "text"
      },
      "source": [
        "**PADDING THE DOCS (to make very doc of same length)**\n",
        "\n",
        "The Keras Embedding layer requires all individual documents to be of same length. Hence we wil pad the shorter documents with 0 for now. Therefore now in Keras Embedding layer the 'input_length' will be equal to the length (ie no of words) of the document with maximum length or maximum number of words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfX8_OTWjYp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxpVKspnjY2J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "999e6dc7-da2a-4432-a050-892c4d7f41fe"
      },
      "source": [
        "sent_length=8\n",
        "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
        "print(embedded_docs)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  0  0  0 10 33 48 17]\n",
            " [ 0  0  0  0 10 33 48 46]\n",
            " [ 0  0  0  0 10 48 48 43]\n",
            " [ 0  0  0 21 39 16  5 46]\n",
            " [ 0  0  0 21 39 16  5 37]\n",
            " [ 0  0  0 37 10 41 48 31]\n",
            " [ 0  0  0  0 13 11 29  5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a3SK8NWjZFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dim=10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bngZRz-jlbUo",
        "colab_type": "text"
      },
      "source": [
        "**PARAMETERS OF THE EMBEDDING LAYER**\n",
        "\n",
        "'input_dim' = the vocab size that we will choose. In other words it is the number of unique words in the vocab.\n",
        "\n",
        "'output_dim' = the number of dimensions we wish to embed into. Each word will be represented by a vector of this much dimensions.\n",
        "\n",
        "'input_length' = lenght of the maximum document. which is stored in maxlen variable in our case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDV0BcK5jZTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(voc_size,10,input_length=sent_length))\n",
        "model.compile('adam','mse')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRS-6VH5jZj3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "68a612d7-1ebe-42e2-9892-496fa8f35083"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 8, 10)             500       \n",
            "=================================================================\n",
            "Total params: 500\n",
            "Trainable params: 500\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6BjVaYDk2sV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "85b2d92f-032a-4c3c-a2c8-875a89a383d3"
      },
      "source": [
        "print(model.predict(embedded_docs)[0]) # sentance 1 representation "
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.02733698 -0.02462319 -0.03820319 -0.03506496 -0.0313495  -0.04966043\n",
            "   0.0421304   0.00937941  0.02608326 -0.04202484]\n",
            " [-0.02733698 -0.02462319 -0.03820319 -0.03506496 -0.0313495  -0.04966043\n",
            "   0.0421304   0.00937941  0.02608326 -0.04202484]\n",
            " [-0.02733698 -0.02462319 -0.03820319 -0.03506496 -0.0313495  -0.04966043\n",
            "   0.0421304   0.00937941  0.02608326 -0.04202484]\n",
            " [-0.02733698 -0.02462319 -0.03820319 -0.03506496 -0.0313495  -0.04966043\n",
            "   0.0421304   0.00937941  0.02608326 -0.04202484]\n",
            " [ 0.00321686  0.02367604 -0.03264217 -0.04508371 -0.03884301 -0.02859296\n",
            "  -0.01672667 -0.00439918 -0.03695983 -0.04182911]\n",
            " [ 0.04063671  0.00095975  0.02020803 -0.00051867 -0.02977251 -0.01185254\n",
            "   0.01610792 -0.01607718 -0.04178732 -0.02081467]\n",
            " [ 0.03244043 -0.01470071 -0.03146     0.04871193 -0.01202101  0.03124345\n",
            "   0.00466467  0.0421304   0.02695843  0.0304435 ]\n",
            " [ 0.03362418 -0.04256827 -0.02428982  0.02579491 -0.0479595  -0.01110294\n",
            "  -0.01982902  0.00185269  0.0046014  -0.0439818 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfsWuqnjk27X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5f07afe-a61f-44b8-cc89-85136694fb01"
      },
      "source": [
        "embedded_docs[0]"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  0,  0,  0, 10, 33, 48, 17], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqmIOkMpk3Ib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}